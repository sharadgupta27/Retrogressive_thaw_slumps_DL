#the parameter file for deep learning network setting


##############################################################

tf_research_dir = ~/codes/PycharmProjects/tensorflow/yghlc_tf_model/research
tf1x_python  = ~/programs/miniconda3/envs/tf1.14/bin/python

# defined the pre-trained model, trained on imagenet
pre_trained_model_folder = ~/Data/deeplab/v3+/pre-trained_model
pre_trained_model_url = http://download.tensorflow.org/models/resnet_v1_101_2018_05_04.tar.gz
TF_INIT_CKPT = resnet_v1_101_2018_05_04.tar.gz
tf_initial_checkpoint = resnet_v1_101/model.ckpt
model_variant = resnet_v1_101_beta

## training parameter
batch_size=8

# the number of iteration
iteration_num=100

# if this is set, iteration_num will be ignored, then iteration_num=train_epoch_num*train_sample_count/batch_size
train_epoch_num = 50

#base_learning_rate
# Use 0.007 when training on PASCAL augmented training set, train_aug. When
# fine-tuning on PASCAL trainval set, use learning rate=0.0001. (from deeplab train.py)
base_learning_rate=0.007

# For `xception_65`, use atrous_rates = [12, 24, 36] if output_stride = 8, or
# rates = [6, 12, 18] if output_stride = 16. Note one could use different
# atrous_rates/output_stride during training/evaluation. (from deeplab train.py)
train_output_stride=16
train_atrous_rates1=6
train_atrous_rates2=12
train_atrous_rates3=18

inf_output_stride=8
inf_atrous_rates1=12
inf_atrous_rates2=24
inf_atrous_rates3=36

# decoder output stride
decoder_output_stride = 4

# 1 for export multi scale frozen inference graph, 0 for single-scale
export_multi_scale = 1


# batch size for inference
# (After update DeepLab repo on 18 Jan 2021, the export_model.py go back to original version which only accepts inf batch size as 1)
inf_batch_size=1
##############################################################

